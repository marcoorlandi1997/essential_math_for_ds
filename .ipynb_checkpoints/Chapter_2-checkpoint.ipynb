{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7b1e293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libriaries\n",
    "from scipy.stats import binom, beta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a73bd63",
   "metadata": {},
   "source": [
    "# Understanding Probability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cefa4ce",
   "metadata": {},
   "source": [
    "The most popular way to express probability is as a percentage, as in \"There is a 70% chance my flight will be late\". We call this probability $P(X)$ where $X$ is the event of interest. However, it is more likely to see it expressed as a decimal: $P(X) = 0.70 or P(X) = .70$.\n",
    "\n",
    "In Statistics we have another concept close to probability which is $Likelyhood$. To get used to these 2 terms we can specify that:\n",
    "- Probability quantifies predictions of events yet to happen;\n",
    "- Likelyhood measure the frequency of event that already occured.\n",
    "\n",
    "Thus, you can use Likelyhood in the form of data to predict probabilities of future events.\n",
    "\n",
    "In addition, if we have $P(X) = .70$ that means $P(not X) = 1 - .70 = .30$, since the probability of an event must be between $0.0$ and $1.0$ or alternatively between $0%$ and $100%$.\n",
    "Moreover, probabilities of all possibile mutually exclusive outcomes for an event must sum to 100%, whereas this rule does not apply to Likelyhoods.\n",
    "\n",
    "We can introduce the concept of $Odds$, such as $O(X) = \\dfrac{7}{3}$. We can turn this into a proportional probability: $P(X) = \\dfrac{O(X)}{1 + O(X)}$.\n",
    "From $P(X)$ to $O(X)$: $O(X) = \\dfrac{P(X)}{1 - P(X)}$.\n",
    "What does it mean $O(X) = 2.0$? It means that we think that the event $X$ is two times more likely to happen. Odds are helpful quantifying subjective beliefs especially in gambling/betting contexts, and it plays a role in Bayesian Stats as well as Log. regressions with log-odds."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32400326",
   "metadata": {},
   "source": [
    "# Probability versus Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ab39a6",
   "metadata": {},
   "source": [
    "Probability is a pure theoretical way to compute how likely is an event to occur and it does not require data. Instead, Statistics cannot exists without data and it uses it to discover prabilities and provides tools to describe data.\n",
    "Think of it in the following way:\n",
    "- If you have a fair die you could say there is a probability of getting 4 on a roll of $1/6$. So, in this situation it would be silly to collect data on several rollings to get the probability. However, if the die is not fair, collecting data is the only way to get the actual probability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e54d12",
   "metadata": {},
   "source": [
    "# Probability Math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddc16dd",
   "metadata": {},
   "source": [
    "When we work with a single probability of an event $P(X)$, this is known as $marginal probability$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80841119",
   "metadata": {},
   "source": [
    "## Joint Probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70caf27e",
   "metadata": {},
   "source": [
    "Let's say we want to find out the probability of getting a 6 on rolling a die and a heads flipping a coin, assuming they are fair. In order to get the intuition behind this, we first assume these two events are indipendent. Then, we can think of them, using the $AND$ operator, meaning that we want to discover the joint probability that either the first and the second event will occur. We can write it down in this way:\n",
    "- $P(A$ $and$ $B)$\n",
    "\n",
    "We know the probability of getting a 6 on rolling a die is $1/6$ whereas the probability of getting a heads is $1/2$. Then, instead of computing the whole set of combinations and getting the probability of that event, we can just use the $product$ $rule$ which says that we can get the joint probability of two (or more) events that are indipendent in the following way:\n",
    "- $P(A$ $and$ $B) = P(A) * P(B) = 1/6 * 1/2 = 1/12 = 0.08333$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e9e159",
   "metadata": {},
   "source": [
    "## Union Probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04bffa1",
   "metadata": {},
   "source": [
    "But what about the probability of getting event $A$ or $B$? Here, we're dealing with $OR$ operations, known as well as $union$ $probabilities$.\n",
    "\n",
    "We have 2 kind of cases to consider here:\n",
    "- If we have mutually exclusive cases, like getting a 4 or a 6 rolling a die we have just to sum up the individual probabilities, thus, $P(4$ $OR$ $6) = \\dfrac{1}{6} + \\dfrac{1}{6} = \\dfrac{2}{6} = \\dfrac{1}{3}$;\n",
    "- But, in the case of non mutually exclusive cases, so, events that can happen at the same time, like getting a heads or a 6 through a flip coin and rolling a die we have to considers also the joint probabilities of those events. Thus, the probability $P(A$ $OR$ $B) = \\dfrac{1}{2} + \\dfrac{1}{6} - P(A$ $AND$ $B) = \\dfrac{1}{2} + \\dfrac{1}{6} - \\dfrac{1}{12} = 0.58333$.\n",
    "\n",
    "However, the joint probabilities exists even in mutually exclusive cases, it's just equal to $0$ there. So, in summary, when we have a union probability we have to remove the joint probability of the events so no probabilities are double counted."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43cf742a",
   "metadata": {},
   "source": [
    "## Conditional Probability and Bayes' Theorem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d915876",
   "metadata": {},
   "source": [
    "A conditional probability is defined as the probability of an event $A$ occuring given event $B$ has occurred. It is express as follows: $P(A | B)$.\n",
    "\n",
    "To understand the concept of conditional probability it would be helpful to introduce an example regarding drinking coffee and cancer.\n",
    "We know from $statista.com$ and $cancer.gov$ that 65% of people drink coffee in the US whereas 0.5% is diagnosed with cancer. In addition we're told from a study that 85% of cancer patients drank coffe.\n",
    "Stated in this way, $P(Coffe-drinker | Cancer)$, coffee seems to be a great problem. However, only 0.5% of the population has cancer while 65% drink coffee. So, if coffee really contributes to having cancer, we should have a higher percentage of the population diagnosed with cancer.\n",
    "\n",
    "The point is, with conditional probabilities the direction has a great impact. Here, the problem should be studied with the opposite direction in order to understand the contribution of coffee to having a cancer, so, what is the probability of having a cancer given the fact you drink coffee? Or differently:\n",
    "- $P(Cancer | Coffe-drinker)$.\n",
    "\n",
    "To do so, we need to apply the Bayes' Theorem in order to reverse a conditional probability through the use of the following formula:\n",
    "- $P(A | B) = \\dfrac{P(B | A)*P(A)}{P(B)}$.\n",
    "Doing so, we get: $P(Cancer | Coffe-drinker) = \\dfrac{.85*.005}{.65} = .0065$. That means, that the probability of having a cancer given the fact you're drinking coffee is just about 0.65%.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6507ed3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.006538461538461539\n"
     ]
    }
   ],
   "source": [
    "# Example 2-1 - Using Bayes' Theorem to flip conditional probabilities\n",
    "p_coffe_drinker = .65\n",
    "p_cancer = .005\n",
    "p_coffee_drinker_given_cancer = .85\n",
    "\n",
    "p_cancer_given_coffee_driker = (p_coffee_drinker_given_cancer * p_cancer) / p_coffe_drinker\n",
    "print(p_cancer_given_coffee_driker)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61745163",
   "metadata": {},
   "source": [
    "## Joint and Union Conditional Probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b07609",
   "metadata": {},
   "source": [
    "If event $A$ has no impact on event $B$, then this means $P(B|A) = P(B)$. Therefore, regardless of the fact the two events $A$ and $B$ are dependent, the Joint Probability becomes: $P(A$ $AND$ $B) = P(A|B) * P(B)$. From the last statement, we can see of $Joint$ $Probabilities$ and $Conditional$ $Probabilities$ are related.\n",
    "\n",
    "Instead, if we want to calculate the probability of $A$ or $B$ occuring, with $A$ that may have an impact on $B$, then our sum rule becomes: $P(A$ $OR$ $B) = P(A) + P(B) - P(A|B) * P(B)$. The last part, is just $P(A$ $AND$ $B) = P(A|B) * P(B)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888c5d24",
   "metadata": {},
   "source": [
    "# Binomial Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33cd28ae",
   "metadata": {},
   "source": [
    "Let's say we're working on a new turbine jet engine and we ran 10 tests. The outcomes yelded 8 successes and 2 failures. We were hoping for a 90% success rate. Our engineer says we should run more tests before going to the drawing board to re-design the project. \n",
    "In this case we could use the binomial distribution in order to measures how likely $k$ successes can happen out of $n$ trials given the underlying probability $p$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03605796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - 9.999999999999978e-11\n",
      "1 - 8.999999999999978e-09\n",
      "2 - 3.6449999999999943e-07\n",
      "3 - 8.747999999999991e-06\n",
      "4 - 0.00013778099999999974\n",
      "5 - 0.0014880347999999982\n",
      "6 - 0.011160260999999996\n",
      "7 - 0.05739562799999997\n",
      "8 - 0.1937102444999998\n",
      "9 - 0.38742048899999976\n",
      "10 - 0.3486784401000001\n"
     ]
    }
   ],
   "source": [
    "# Example 2-2 Using SciPy for the binomial distribution\n",
    "n = 10  # Number of trials\n",
    "p = .9  # Probability of success for each trial\n",
    "\n",
    "# K is the positive outcome\n",
    "for k in range(n + 1):\n",
    "    probability = binom.pmf(k, n, p)\n",
    "    print(f\"{k} - {probability}\")\n",
    "# This script tells us the probability of getting K successes out of 10 trials"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb24186",
   "metadata": {},
   "source": [
    "From the example you see the probability of getting 8 or fewer successes would give us .2639 probability. Thus, it makes sense doing other tests. Instead the probability of getting 0 successes it is really unlikely. The highest probability is found at 9."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bdfc8d2",
   "metadata": {},
   "source": [
    "# Beta Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce151bd2",
   "metadata": {},
   "source": [
    "What might be problematic about our binomial distribution is that we assumed 90% success rate. We just showed the underlying success rate is 90% and so, there is also a 26.39% chance we would get 8 or fewer successes with 10 trials.\n",
    "So, with this in mind we would like to explore the probability of probabilities.\n",
    "So rather than create countless binomial distribution to answer this question there is one tool we can use which is called beta distribution. This allows us to see the likelihood of different underlying probabilities for an event to occur given alpha successes and beta failures.\n",
    "The beta distribution is a continuous function meaning it forms a continuous curve of decimal values.\n",
    "The beta distribution is a type of probability distribution, which means the area under the entire curve is 1.0 or 100%. Then, if we want to get the probability $\\dfrac{8}{10}$ successes would yeld 90% or more we need to find the area between 0.9 and 1.0.\n",
    "Every continuos probability distribution has a cumulative density function which calculates the area up to a given x-value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "268c615c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7748409780000002\n"
     ]
    }
   ],
   "source": [
    "# Example 2-3 Beta distribution using ScyPy\n",
    "a = 8  # The number of successes\n",
    "b = 2  # Number of failures\n",
    "\n",
    "p = beta.cdf(.9, a, b)  # The first argument is the value on the x-axis\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5a3303f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22515902199999982\n"
     ]
    }
   ],
   "source": [
    "# Example 2-4 Subtracting to get a right area in a beta distribution\n",
    "a = 8  # The number of successes\n",
    "b = 2  # Number of failures\n",
    "\n",
    "# Get the probability of getting more than 9 successes\n",
    "p = 1 - beta.cdf(.9, a, b)  # The first argument is the value on the x-axis\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b199e2",
   "metadata": {},
   "source": [
    "This means there is just a 22.5% that the underlying success rate is greater then 90%, whereas there is a 77.50% chance it is lower than 90%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b3d0f88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13163577484183697\n"
     ]
    }
   ],
   "source": [
    "# Example 2-5 More trials\n",
    "a = 30  # The number of successes\n",
    "b = 6  # Number of failures\n",
    "\n",
    "# Get the probability of getting more than 90% success rate\n",
    "p = 1 - beta.cdf(.9, a, b)  # The first argument is the value on the x-axis\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de710c4",
   "metadata": {},
   "source": [
    "In this case, we increased the number of trials, and we got a smaller success rate to get $\\dfrac{9}{10}$ or more. So, we should stop doing test and re-design the jet engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b372e62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.33863336199999994\n"
     ]
    }
   ],
   "source": [
    "# Example 2-6 Get a middle area probability between 0.8 and 0.9\n",
    "a = 8  # The number of successes\n",
    "b = 2  # Number of failures\n",
    "\n",
    "p = beta.cdf(.9, a, b) - beta.cdf(.8, a, b)\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01dc984",
   "metadata": {},
   "source": [
    "There is a 33.86% to yeld a success rate between 80% and 90%."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
