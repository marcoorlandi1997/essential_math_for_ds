{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f87f1249",
   "metadata": {},
   "source": [
    "# Descriptive and Inferential Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820a8cf5",
   "metadata": {},
   "source": [
    "## Descriptive versus Inferential Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2784b4",
   "metadata": {},
   "source": [
    "The most understood part of statistics is called $Descriptive$ $Statistics$, where are used tools as the mean, the median, the mode, charts, bell curves and tool to summarize the date we have.\n",
    "Instead, what is called $Inferential$ $Statistics$ is less intuitive, it tries to uncover attributes about a larger population often based on a sample. In additiom, this sample may have several problems, for example, it could not represent the actual population."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91be5365",
   "metadata": {},
   "source": [
    "## Population, Samples and Bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b042d4",
   "metadata": {},
   "source": [
    "Population is a particular group of interest we want to study such as \"all seniors over the age of 65 in the North America\", or \"all golden retrievers in Scotland\" or \"current high school sophomores at Los Altos high school\". Notice how we have boundaries defining our population, and some of these boundaries are broad and captures a large population over a vast geography or age group, whereas others are highly specific as the last example. So defining a population depends essentially on what you are interested in."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157bcf5f",
   "metadata": {},
   "source": [
    "If we are going to infer attributes about the population based on a sample, it's really important the sample to be as random as possible, so we do not skew our conclusions. For example, if I want to find the average number of hours college students watch televisions per week in the United States I can walk right outside my door and start pulling random students walking by. However, here there is a big problem because our student sample is going to have a bias, meaning it skews our findings by over representing a certain group at the expense of other groups. Indeed, my study, defined the population to be college students in the United States and not college students at Arizona State University. Ideally, I should be randomly pulling college students all over the country at different universities, so, in that way, I should have a more representative sample."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ea654c",
   "metadata": {},
   "source": [
    "Let's make another example. I could encounter a $self$-$selection$ bias through the collection of this kind of information through social media like Twitter and Facebook. Why? Because the people that he's going to fill out the questionnaire is more likely to watch TV, or to have Netflix, thus, watching more hours compared to those that are not on these social media."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd895d48",
   "metadata": {},
   "source": [
    "Seen in this way it seems that bias is inevitable and in many cases it is, so, there could be many confounding variables or factors we didn't account for that can influence our study. Thus, this problem of data bias is expensive and difficult to overcome and of course, machine learning is especially vulnerable to it. The way to overcome this problem is to select students from the entire population, so they cannot elect themselves into or out of the sample voluntarily. This represents the most effective way to mitigate bias but as you can imagine, it takes a lot of coordinated resources to do."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f5f095",
   "metadata": {},
   "source": [
    "There are many type of bias, but they all have the same effect of distorting findings. We could have confirmation bias, so, gathering information that supports our belief, even unknowingly. An example of this bias is to follow only those social media accounts that you politically agree with, reinforcing your beliefs, rather than challenging them.\n",
    "Another type of bias is called survival bias, where are captured only living and survived subjects while the deceased ones are never accounted for.\n",
    "An example of this that comes to mind is related to Steve Jobs. He was said to be passionate and hot tempered, and he also created one of the most valuable companies of all times. Thus, for some people being passionate and a temperate might correlate with success, but again this is survivor bias because there are many, many companies that are run by passionate leaders that have failed in obscurity rather than becoming a success story like Apple."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a80df7c",
   "metadata": {},
   "source": [
    "These stories remind us to always ask questions about how the data was obtained, and then scrutinise how that process could have biased data. As anticipated before these problems with sampling, and bias extends to machine learning as well. Whether it is linear regression, logistic regression, or neural networks, a sample of data is used to infer predictions. If that data is biased, then it will steer the machine learning algorithm to make biased conclusions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c019733d",
   "metadata": {},
   "source": [
    "## Descriptive Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4da326",
   "metadata": {},
   "source": [
    "### Mean and Weighted Mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67facaea",
   "metadata": {},
   "source": [
    "The mean is just the average of a set of values, and it is useful since it gives back where the \"center of gravity\" exists for an observed set of values. In addition, it is computed in the same way either for samples and populations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee82c2b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.833333333333333\n"
     ]
    }
   ],
   "source": [
    "# Example 3-1 Calculating mean in Python\n",
    "sample = [1, 3, 5, 7, 9, 4]\n",
    "\n",
    "mean = sum(sample) / len(sample)\n",
    "print(mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3976c34",
   "metadata": {},
   "source": [
    "As anticipated earlier, we have to versions:\n",
    "- $\\bar{x} = \\dfrac{x_1 + x_2 + x_3 + ... + x_n}{n}$\n",
    "\n",
    "- $\\bar{\\mu} = \\dfrac{x_1 + x_2 + x_3 + ... + x_n}{N}$\n",
    "\n",
    "They represent the same thing, just the denomination is different. In the first case we are computing the mean for a sample whereas in the second case for an entire population. Besides the symbol to display the mean depending on what we're considering, there also a little change in the denominator. Indeed, in the first case with a sample, we indicate its size trough $n$, whereas with a population with $N$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c451f7c",
   "metadata": {},
   "source": [
    "We can of course apply a weight to item in the mean through the weighted mean:\n",
    "- $weighted$ $mean = \\dfrac{x_1*w_1 + x_2*w_2 + x_3*w_3 + ... + x_n*w_n}{w_1 + w_2 + w_3 + ... + w_n}$\n",
    "\n",
    "This is especially useful when we want some values to contribute to the mean more than others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45cde8f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81.4\n"
     ]
    }
   ],
   "source": [
    "# Example 3-2 Calculating a weighted mean in Python\n",
    "# Three exames with .20 weight each and final exam with .40 weight\n",
    "sample = [90, 80, 63, 87]\n",
    "weights = [.20, .20, .20, .40]\n",
    "\n",
    "weighted_mean = sum([s * w for s, w in zip(sample, weights)]) / sum(weights)\n",
    "print(weighted_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779bf2d3",
   "metadata": {},
   "source": [
    "Weightings don't have to be percentages since any number put inside will be proportionalized. See this in the next example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6f64113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81.4\n"
     ]
    }
   ],
   "source": [
    "# Example 3-3 Calculating a weighted mean in Python\n",
    "# Three exames with .20 weight each and final exam with .40 weight\n",
    "sample = [90, 80, 63, 87]\n",
    "weights = [1, 1, 1, 2]\n",
    "\n",
    "weighted_mean = sum([s * w for s, w in zip(sample, weights)]) / sum(weights)\n",
    "print(weighted_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70396b9",
   "metadata": {},
   "source": [
    "### Median"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1fddd2d",
   "metadata": {},
   "source": [
    "The median is the middlemost value in a set of ordered values. If you have an even number of values, you average the two centermost values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cbed00cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "# Example 3-4 Calculating the median in Python\n",
    "def median(values):\n",
    "    values = sorted(values)\n",
    "    n = len(values)\n",
    "    if n % 2 == 0:\n",
    "        mid = int(n/2) - 1\n",
    "    else:\n",
    "        mid = int(n/2)\n",
    "    \n",
    "    if n % 2 == 0:\n",
    "        median = (values[mid] + values[mid + 1]) / 2\n",
    "        return median\n",
    "    else:\n",
    "        median = values[mid]\n",
    "        return median\n",
    "    \n",
    "sample = [0, 1, 5, 7, 9, 10, 14]\n",
    "\n",
    "print(median(sample))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad871b61",
   "metadata": {},
   "source": [
    "Recall that in Python $int(\\dfrac{3}{2})$ returns 1, not 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0149d5",
   "metadata": {},
   "source": [
    "The median can be a helpful alternative to the mean when data is skewed by outliers, or values that are extremely high or low compared to the rest of the values. Thus, when our median is quite different from the mean it means the data is skewed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08f3f4c",
   "metadata": {},
   "source": [
    "Recall that the median is simply the 50% quantile, meaning that the 50% of the ordered values are below that value. In the same way, we could have other quantiles, 25% and 75%, also called quartiles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0bab22c",
   "metadata": {},
   "source": [
    "### Mode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38dff404",
   "metadata": {},
   "source": [
    "The mode is the most frequently occuring set of values. It primarily becomes useful when your data is repetitive and you want to find which values occur the most frequently. When no values occurs more than once, there is no mode. When two values occur with an equal amount of frequency, then the dataset is said to be bimodal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "62602c31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 3-5 Calculating the mode in Python\n",
    "from collections import defaultdict\n",
    "def mode(values):\n",
    "    # We create a dictionary with keys the number and values the occurrencies in the sample\n",
    "    counts = defaultdict(lambda: 0)\n",
    "    for s in values:\n",
    "        counts[s] += 1\n",
    "    \n",
    "    # Highest occurrency\n",
    "    max_count = max(counts.values())\n",
    "    \n",
    "    # Mode\n",
    "    modes = [v for v in set(values) if counts[v] == max_count]\n",
    "    \n",
    "    return modes\n",
    "\n",
    "sample = [1, 3, 2, 5, 7, 0, 2, 3]\n",
    "\n",
    "mode(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c3561a-b677-4695-8da0-d64b40e05bfb",
   "metadata": {},
   "source": [
    "### Variance and Standard Deviation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cdef690-4030-4bfb-a5a4-8a80743779ab",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Population Variance and Standard Deviation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ea6868-eb5b-45ca-8842-b5bec3c6478e",
   "metadata": {},
   "source": [
    "Let's say we want to study the number of pets owned by members of the working staff. Please note that we are defining it as my population, not a sample. In order to measure how spread is the data we have first to compute its mean, and then to subtract the mean from each measure. Once we have done this operation we have to square each result in order to get rid of negative values and in order to amplify differences (it is even mathematically easier to work with). Finally, we sum all of these values and we divide it by the population size."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27cb16e0-36fa-4812-85e4-a80ba3e2328f",
   "metadata": {},
   "source": [
    "Here, the math's formula:\n",
    "\n",
    "- $variance = \\dfrac{(x_1 - mean)^2 + (x_2 - mean)^2 + (x_3 - mean)^2 + ... + (x_n - mean)^2}{N}$\n",
    "\n",
    "- or alternatively, $\\sigma^{2} = \\dfrac{\\sum{(x_i - \\mu)^2}}{N}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ebdfe90-b9d2-428b-9498-92f3f213886b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.387755102040813\n"
     ]
    }
   ],
   "source": [
    "# Example 3-6 Calculating the variance in Python\n",
    "data = [0, 1, 5, 7, 9, 10, 14]\n",
    "\n",
    "def variance(values):\n",
    "    n = len(data)\n",
    "    mean = sum(data) / n\n",
    "    variance = sum([ (value - mean) ** 2 for value in data ]) / n\n",
    "    return variance\n",
    "\n",
    "print(variance(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6b508b-7d31-4d45-b3b8-72bc331b8f5e",
   "metadata": {},
   "source": [
    "Thus, the variance for the number of pets is 21.38. But what does it exactly mean? It's reasonable to assume that the higher is the variance the more spread out is the data. But since we squared our values, we get back a different kind of metrics. So, to squeeze it back down so it's on the scale we started with we apply the square root to the variance in order to get the standard deviation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f7db90-caaf-403d-b9dc-dd339349ccfc",
   "metadata": {},
   "source": [
    "Here, the full formula to get the standard deviation:\n",
    "- $\\sigma = \\sqrt{\\sigma^{2}} = \\sqrt{\\dfrac{\\sum{(x_i - \\mu)^2}}{N}}$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a498aea2-a087-4a65-9a46-bddf194cd037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.624689730353898\n"
     ]
    }
   ],
   "source": [
    "# Example 3-7 Calculating the standard deviation in Python\n",
    "from math import sqrt\n",
    "\n",
    "data = [0, 1, 5, 7, 9, 10, 14]\n",
    "\n",
    "def variance(values):\n",
    "    n = len(data)\n",
    "    mean = sum(data) / n\n",
    "    variance = sum([ (value - mean) ** 2 for value in data ]) / n\n",
    "    return variance\n",
    "\n",
    "def square_root(variance):\n",
    "    return sqrt(variance)\n",
    "\n",
    "print(square_root(variance(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b169de8-b6d0-490c-a1bb-e55499fe26db",
   "metadata": {},
   "source": [
    "We got a standard deviation of 4.62 pets. In this way, we expressed how is spread our data with the original metric."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b777f7-b635-4efe-ba5a-abfbea90b8fa",
   "metadata": {},
   "source": [
    "#### Sample Variance and Standard Deviation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5304c151-ca89-449f-be59-dd3be7776606",
   "metadata": {},
   "source": [
    "In order to get the variance and standard deviation for a sample, instead of a population, we have to do a small adjustment to our formulas.\n",
    "Our sample variance and sample standard deviation become:\n",
    "- $sample$ $variance$ $= s^{2} = \\dfrac{\\sum{(x_i - \\mu)^2}}{n - 1}$\n",
    "- $sample$ $standard$ $deviation$ $= s = \\sqrt{\\dfrac{\\sum{(x_i - \\mu)^2}}{n - 1}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86f2174-9da4-4d73-8d7d-0e8eec04c61c",
   "metadata": {},
   "source": [
    "Thus, we are dividing the sum of squared differences by $n-1$ instead of $N$ to decrease the bias and increase the variance in order to capture a greater uncertainty in our sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c3fe4d7-2c5e-4e60-8e04-594ab1a8cbdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.95238095238095\n",
      "4.99523582550223\n"
     ]
    }
   ],
   "source": [
    "# Example 3-8 Calculating standard deviation for a sample\n",
    "from math import sqrt\n",
    "\n",
    "data = [0, 1, 5, 7, 9, 10, 14]\n",
    "\n",
    "def variance(values, is_sample: bool = False):\n",
    "    n = len(data)\n",
    "    mean = sum(data) / n\n",
    "    variance = sum([ (value - mean) ** 2 for value in data ]) / (len(values) - (1 if is_sample else 0))\n",
    "    return variance\n",
    "\n",
    "def square_root(values, is_sample: bool = False):\n",
    "    return sqrt(variance(values, is_sample))\n",
    "\n",
    "print(variance(data, is_sample=True))  # Sample variance\n",
    "print(square_root(data, is_sample=True))  # Sample standard deviation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc14add-e1bd-4c63-85b5-66939893b8db",
   "metadata": {},
   "source": [
    "We got a higher variance and standard deviation just because of our denominator. This is correct as a sample could be biased and imperfect representing the population."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2c48a5-069a-4e5a-83f6-72b38c01b15b",
   "metadata": {},
   "source": [
    "### Normal Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0adb25b5-22d8-43c9-b8e2-a42934f254bc",
   "metadata": {},
   "source": [
    "The normal distribution, also known as the $Gaussian$ $Distribution$, is a symmetrical bell-shaped distribution that has most mass around the mean, and its spread is defined as a standard deviation. The tails on either side become thinner as you move away from the mean."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72899353-1c81-4e6a-8969-306430413439",
   "metadata": {},
   "source": [
    "#### Properties of a Normal Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2f5c94-d2d1-4f5a-a4b2-45e4c5b2992d",
   "metadata": {},
   "source": [
    "The normal distribution has the following properties:\n",
    "- it's symmetrical, both sides are identically mirrored at the mean, which is the center;\n",
    "- most mass is at the center around the mean;\n",
    "- it has a spread that is specified by the standard deviation;\n",
    "- the tails are the least likely outcomes and approach zero infinetely but never touch zero;\n",
    "- it resembles a lot of phenomena in nature and daily life, even non-normal problems through the center limit theorem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a22ffc8-ce5c-414a-b683-44db822bce90",
   "metadata": {},
   "source": [
    "#### The Probability Density Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d1f424-c384-47d3-af58-c25d76e8ded6",
   "metadata": {},
   "source": [
    "The standard deviation plays an important role in the normal distribution, because it defines how spread out it is. It is actually one of the parameters alongside the mean. The probaiblity density function that creates the normal distribution is as follows:\n",
    "\n",
    "- $f(x) = \\dfrac{1}{\\sigma} * \\sqrt{2*\\pi} * e^{-\\dfrac{1}{2} * (\\dfrac{x-\\mu^2}{\\sigma})}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7853754-237e-4bdb-86f3-c92484a587ea",
   "metadata": {},
   "source": [
    "Just like the beta distribution the normal distribution is continuous. This means to retrieve a probability we need to integrate a range of $x$ values to find an area."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0c9dd4-157d-403f-b6a2-9a73e79e14e2",
   "metadata": {},
   "source": [
    "#### The Cumulative Distribution Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb24d67-c573-4fd5-a175-3343e71c166e",
   "metadata": {},
   "source": [
    "With the normal distribution, the vertical axis is not the probability but the likelihood for the data. To find the probability we need to look at a given range and then fin the area under the curve for that range."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad2c72b-ebc9-45a7-9e29-a8f0d8a1a383",
   "metadata": {},
   "source": [
    "There's a relationship between the PDF and the CDF. The CDF is a S-shaped curve that prjects the area up to that range in the PDF. Indeed, if we try to capture the area from negative infinity to the mean of the normal distribution our CDF shows a value of .5 or 50%. That it is because of the symmetry of the normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "682c53f0-fcc4-47a0-85cb-14774525f701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    }
   ],
   "source": [
    "# Example 3-10 The normal distribution CDF in Python\n",
    "from scipy.stats import norm\n",
    "\n",
    "mean = 64.43\n",
    "std_dev = 2.99\n",
    "\n",
    "x = norm.cdf(64.43, mean, std_dev)  # CDF up to 64.43\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e7f019-9558-4b5b-b9d7-4ac58bb88801",
   "metadata": {},
   "source": [
    "We have a 50% probability of observing a value up to 64.43."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "777a07c4-e642-43c8-895d-52a48582c075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4920450147062894\n"
     ]
    }
   ],
   "source": [
    "# Example 3-11 Getting a middle range probability using the CDF in Python\n",
    "from scipy.stats import norm\n",
    "\n",
    "mean = 64.43\n",
    "std_dev = 2.99\n",
    "\n",
    "x = norm.cdf(66, mean, std_dev) - norm.cdf(62, mean, std_dev)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72d675f-7a84-4e2f-ada0-718008c403b2",
   "metadata": {},
   "source": [
    "We have a 49.20% probability of observing a value between 66 and 62."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
