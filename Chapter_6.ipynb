{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c47c54fe-cfa0-4992-93af-133cdd07712e",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8b2d64-19a4-4b62-9af7-1bc4a5d89506",
   "metadata": {},
   "source": [
    "The logistic regression is a type of regression that predicts a probability of an outcome given one or more indipendent variables (input columns). This method can be used for clasification, which means predicting categories rather than numbers.\n",
    "Indeed, there are situations where we would the variables to be discrete rather than continuos. So, the logistic regression is trained on an output variable that is discrete (0 or 1) or categorical (whole numbers, as 1, 2, 3 and 4), and it gives back a probability as a result that can be converted into a discrete value with a threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1e0acf-1540-4b7a-ad71-937738506f55",
   "metadata": {},
   "source": [
    "## Performing a Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e526c780-4d7d-4eb2-bf8b-955c869b0592",
   "metadata": {},
   "source": [
    "The logistic function is an S-shaped curve, also known as $sigmoid$ $curve$, that for a given set of input variables, produces an output variable between 0 and 1. And because of that, it can be used to represent a probability.\n",
    "Here the logistic function that outputs a probability $y$ for one input variable $x$:\n",
    "- $p = \\dfrac{1.0}{1.0 + e^{-(\\beta_0 + \\beta_1x_1)}}$\n",
    "\n",
    "The $x$ variable is the independent or the input variable, whereas $\\beta_0$ and $\\beta_1$ are the coefficients we need to solve for. We can see a linear function in the exponent, which in this case is known as the log-odds function. As in the case of linear regression, we can extend the logistic regression to more than one input variable as shown in the following formula:\n",
    "- $p = \\dfrac{1.0}{1.0 + e^{-(\\beta_0 + \\beta_1x_1 + \\beta_2x_2 + ...)}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f6d9f07-8e60-4052-a59e-80aab13c4c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 6-1 The logistic function in Python for one indipendent variable\n",
    "import math\n",
    "\n",
    "def predict_probability(x, b0, b1):\n",
    "    p = 1.0 / (1.0 + math.exp(-(bo + b1 * x)))\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "448b8f84-c420-473c-af49-d95eeba6ae9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0/(1.0 + 16.8272567955368*exp(-0.62*x))\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<sympy.plotting.plot.Plot at 0x166a5d248e0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sympy import *\n",
    "# Define our vars\n",
    "b0, b1, x = symbols('b0 b1 x')\n",
    "\n",
    "# Logistic function\n",
    "p = 1.0 / (1.0 + exp(-(b0 + b1 * x)))\n",
    "\n",
    "# Plug in values for b0 and b1\n",
    "p = p.subs(b0, -2.823)\n",
    "p = p.subs(b1, 0.62)\n",
    "print(p)\n",
    "\n",
    "# Plot it\n",
    "plot(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee607d87-32c0-4a70-a33a-a5b359a6d4cb",
   "metadata": {},
   "source": [
    "## Fit the Logistic Curve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b1ff00-0719-4347-b9bf-34bff7c4ee8e",
   "metadata": {},
   "source": [
    "In order to fit a logistic curve to a given training data set, we need the output variable must be. Then we need to solve for the beta zero and beta one with fusions to fit our logistic function. But instead of using least squares, as in the case of a linear regression, here we use the maximum likelihood estimation. Which maximizes the likelihood and give a logistic curve with output the observed data.\n",
    "\n",
    "In other words, the MLE is an approach used to compute the coefficients ($\\beta_0$, $\\beta_1$, ...) so that our logistic curve (see the above logistic function) with these coefficients plugged in is going to output the observed data, of course, as closely as possible to the observed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b9054b7c-283b-4d83-bdbc-9e73e1cce56f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-3.17576395] [0.69267212]\n"
     ]
    }
   ],
   "source": [
    "# Example 6-3\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# DF\n",
    "df = pd.read_csv(\"https://bit.ly/33ebs2R\", delimiter=\",\", header=0)\n",
    "df.head()\n",
    "\n",
    "# Extract input vars\n",
    "X = df.values[:, :-1]\n",
    "# Extract output var\n",
    "Y = df.values[:, -1]\n",
    "\n",
    "# Logistic function\n",
    "model = LogisticRegression(penalty=\"none\")  # Otherwise it uses a Ridge or Lasso Regression\n",
    "model.fit(X, Y)\n",
    "b0 = model.intercept_.flatten()  # Withouth flatten it returns [[0.69267212]]. So, the aim \n",
    "# of using flatten is to reduce the dimensionality of the matrix considered\n",
    "b1 = model.coef_.flatten()\n",
    "print(b0, b1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b63d9b0-927c-4e29-a6cc-4eccace392d0",
   "metadata": {},
   "source": [
    "SKIP from page 200 to 204. There are discussed how to find manually the coefficients through Gradient Descent on logistic regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea91588d-5406-4070-9385-2b29ebbcbde8",
   "metadata": {},
   "source": [
    "## Multivariable Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e6675c37-8c00-479c-aa52-5f6268cbdfed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   SEX  AGE  PROMOTIONS  YEARS_EMPLOYED  DID_QUIT\n",
      "0    0   25           2               3         0\n",
      "1    0   30           2               3         0\n",
      "2    0   26           2               3         0\n",
      "3    0   25           1               2         0\n",
      "4    0   28           1               2         0\n",
      "Coefficients: [ 0.03213405  0.03682453 -2.50410028  0.9742266 ]\n",
      "Intercept: [-2.73485302]\n",
      "Prediciton: [0]\n",
      "Probabilities: [0.90856497 0.09143503]\n"
     ]
    }
   ],
   "source": [
    "# Example 6-9 Doing a multivariable logistic regression on employees data\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# DF\n",
    "df = pd.read_csv(\"https://tinyurl.com/y6r7qjrp\", delimiter=\",\", header=0)\n",
    "print(df.head())\n",
    "\n",
    "# Inputs\n",
    "inputs = df.values[:, :-1]\n",
    "# Outputs\n",
    "output = df.values[:, -1]\n",
    "\n",
    "# Model\n",
    "fit = LogisticRegression(penalty=\"none\").fit(inputs, output)\n",
    "print(\"Coefficients:\", model.coef_.flatten())\n",
    "print(\"Intercept:\", model.intercept_.flatten())\n",
    "\n",
    "# Make a prediction and compute its probabilities\n",
    "prediction = fit.predict([[0, 27, 1, 2]])\n",
    "probability = fit.predict_proba([[0, 27, 1, 2]])\n",
    "print(\"Prediciton:\", prediction)  # The employee does not quit\n",
    "print(\"Probabilities:\", probability.flatten())  # The probability the employee does not quit is 90.85% whereas he does is at 9.14%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f505fe-a51b-472d-b18f-65708a1e07c0",
   "metadata": {},
   "source": [
    "As shown above the predict_proba() functions returns an array with 2 values, the first being the probability to not quit (False, 0) and the second to quit (True, 1).\n",
    "We also see the first 2 coefficients are quite low, almost 0, meaning that are not so useful here in this case whereas the other 2 are stronger. In addition, recall that in order to make a meaningful prediction we need to test within the range of our data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ce10a8-99da-4740-a4ce-0caa512edb1e",
   "metadata": {},
   "source": [
    "## Understanding the Log-Odds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6948a12-ab1b-47f2-b61d-c25232d01745",
   "metadata": {},
   "source": [
    "Before we defined the exponent value as a linear function ($\\beta_0 + \\beta_1x$). Recall the logistic function:\n",
    "- $p = \\dfrac{1.0}{1.0 + e^{-(\\beta_0 + \\beta_1x_1)}}$\n",
    "\n",
    "Specifically, this linear function is called $log-odds$ function, why so?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7939a6b-4dc7-47ea-a1a4-978b8cfc9dc8",
   "metadata": {},
   "source": [
    "If we recall previous result regarding the simple logistic function:\n",
    "- $\\beta_0 = -3.17576395$; \n",
    "- $\\beta_1 = 0.69267212$.\n",
    "\n",
    "Then, if we wanted to compute the probability of having a sympthom aftwer 6 hours ($x = 6$) we really just need to plug these values into the logistic function, so:\n",
    "- $p = \\dfrac{1.0}{1.0 + e^{-(\\beta_0 + \\beta_1x_1)}}$ = $p = \\dfrac{1.0}{1.0 + e^{-(-3.17576395 + 0.69267212*6)}}$ = $0.72716$.\n",
    "\n",
    "Let's see this from a odd perspective and compute the odds through the formula we learned in Chapter 2:\n",
    "- $odds = \\dfrac{p}{1 - p}$ = $\\dfrac{0.72716}{1 - 0.72716}$ = $2.6651$.\n",
    "\n",
    "This result tells us that after 6 hours a patient is 2.6 times more likely to show symptoms than not show symptoms. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9f470c-5cb0-4bc6-bfd0-7d93b620157f",
   "metadata": {},
   "source": [
    "But how do we get the log-odds? Changing the odds formula into a natural logarithm:\n",
    "- logit function = $log(\\dfrac{p}{1 - p})$ = $log(\\dfrac{0.72716}{1 - 0.72716})$ = $0.9802$.\n",
    "\n",
    "The result coming from the logit function is the log-odds. We treat the results  greater than 0 as favoring odds an event will happen whereas anything less than 0 is against an event. Moreover, a log-odds of -1.05 is linearly the same distance from 0 to 1.05, whereas this equivalent does not hold in plain odds, meaning there is a lack of symmetry."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e222fa0b-7006-4dc1-9bee-82e3a0a1f975",
   "metadata": {},
   "source": [
    "Now, we can show how the result coming from the logit function, so, the log-odds, is the same result coming from the initial linearn function in the exponent:\n",
    "- $\\beta_0 + \\beta_1x$ = $-3.17576395 + 0.69267212*6$ = $0.9802$.\n",
    "\n",
    "That's why we call this linear function, the log-odds function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8471f3d-1980-46ea-b223-052daa3552e1",
   "metadata": {},
   "source": [
    "Another benefit from using odds is that we can compare different x-values. For example, let's find the $p$ for 6 and 8 hours:\n",
    "- $p_6 = \\dfrac{1.0}{1.0 + e^{-(-3.17576395 + 0.69267212*6)}}$ = $0.72716$;\n",
    "- $p_8 = \\dfrac{1.0}{1.0 + e^{-(-3.17576395 + 0.69267212*8)}}$ = $0.9141$.\n",
    "\n",
    "Then, convert it to plain odds:\n",
    "- $o_6 = $\\dfrac{0.72716}{1 - 0.72716}$ = $2.6651$;\n",
    "- $o_8 = $\\dfrac{0.9141}{1 - 0.9141}$ = $10.6505$.\n",
    "\n",
    "Then, we compute the odds-ratio where the odds for 8 is the numerator and for 6 the denominator:\n",
    "- $\\dfrac{10.6505}{2.6651}$ = $3.9962$.\n",
    "\n",
    "This means that our odds of showing sympthoms increases by nearly a factor of 4 with an extra 2-hours of exposure. This value holds across any 2-hour range, from 2 to 4, from 4 to 6...\n",
    "However, this value will different for other range lenghts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c94b3c2-4870-481c-9488-7b3cf53b5c9a",
   "metadata": {},
   "source": [
    "## R-Squared"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d994fcf-5d1c-41b9-adf9-2096c1858b71",
   "metadata": {},
   "source": [
    "Just like in linear regression there is an $R^2$, which indicates how well a given indipendent variable explains a dependent one, even for logistic regression.\n",
    "However, there is not a consensus on the best way to calculate it in this case. A popular technique is the $Pseudo\\;R^2$ which mimics the one employed for linear regressions:\n",
    "- $Pseudo\\;R^2 = \\dfrac{log\\;likelyhood - log\\;likelyhood\\;fit}{log\\;likelyhood}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d115d5a-297f-4c8c-a513-f8a843365b41",
   "metadata": {},
   "source": [
    "In order to get the $log\\;likelyhood\\;fit$ we have to take the log() of each point on the logistic curve and sum them, considering as well that we need to convert the false likelyhoods by subtracting from 1.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6c8080a-3eca-4270-8f14-3807f0943f37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-9.946161673231583\n"
     ]
    }
   ],
   "source": [
    "# Example 6-10 Calculating the log-likelyhood of the fit\n",
    "from math import log, exp\n",
    "import pandas as pd\n",
    "\n",
    "# Data\n",
    "patient_data = pd.read_csv(\"https://bit.ly/33ebs2R\", delimiter=\",\").itertuples()\n",
    "\n",
    "# Set beta0 and beta1\n",
    "b0 = -3.17576395\n",
    "b1 = 0.69267212\n",
    "\n",
    "\n",
    "# Logistic function\n",
    "def logistic_function(x):\n",
    "    p = 1.0 / (1.0 + exp(-(b0 + b1 * x)))\n",
    "    return p\n",
    "\n",
    "# Log-likelyhood fit\n",
    "log_likelyhood_fit = sum(log(logistic_function(p.x)) * p.y + \\\n",
    "                         log(1.0 - logistic_function(p.x)) * (1.0 - p.y) for p in patient_data)\n",
    "print(log_likelyhood_fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6920185c-0a76-493d-8d74-bf8a4e168739",
   "metadata": {},
   "source": [
    "Then, we need to compute the $log\\;likelyhood$ to do so we first compute the $likelyhood$:\n",
    "- $likelyhood$ = $\\dfrac{\\sum{y_i}}{n}$.\n",
    "\n",
    "Then, as before, we do so for each point and we account for false likelyhoods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dabc8ae4-3242-4631-8ec2-55bcfc14713a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-14.341070198709906\n"
     ]
    }
   ],
   "source": [
    "# Example 6-13 Log likelyhood of patients\n",
    "from math import log, exp\n",
    "import pandas as pd\n",
    "\n",
    "# Data\n",
    "patient_data = list(pd.read_csv(\"https://bit.ly/33ebs2R\", delimiter=\",\").itertuples())\n",
    "\n",
    "# Set beta0 and beta1\n",
    "b0 = -3.17576395\n",
    "b1 = 0.69267212\n",
    "\n",
    "\n",
    "# Logistic function\n",
    "def logistic_function(x):\n",
    "    p = 1.0 / (1.0 + exp(-(b0 + b1 * x)))\n",
    "    return p\n",
    "\n",
    "likelyhood = sum(p.y for p in patient_data) / len(patient_data)\n",
    "log_likelyhood = sum(log(likelyhood) * p.y + \\\n",
    "                         log(1.0 - likelyhood) * (1.0 - p.y) for p in patient_data)\n",
    "print(log_likelyhood)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907cf0d0-a699-47f6-8b99-169a84bdd014",
   "metadata": {},
   "source": [
    "Then, we just need to plug these values into the previous cited formula in order to get back $R^2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "94046a33-c7a6-4f8d-9b43-20fc5196981c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.306456105756576\n"
     ]
    }
   ],
   "source": [
    "# Example 6-14 R^2 fpr a logistic regression\n",
    "from math import log, exp\n",
    "import pandas as pd\n",
    "\n",
    "# Data\n",
    "patient_data = list(pd.read_csv(\"https://bit.ly/33ebs2R\", delimiter=\",\").itertuples())\n",
    "\n",
    "# Set beta0 and beta1\n",
    "b0 = -3.17576395\n",
    "b1 = 0.69267212\n",
    "\n",
    "\n",
    "# Logistic function\n",
    "def logistic_function(x):\n",
    "    p = 1.0 / (1.0 + exp(-(b0 + b1 * x)))\n",
    "    return p\n",
    "\n",
    "# Log-likelyhood fit\n",
    "log_likelyhood_fit = sum(log(logistic_function(p.x)) * p.y + \\\n",
    "                         log(1.0 - logistic_function(p.x)) * (1.0 - p.y) for p in patient_data)\n",
    "\n",
    "# Log-likelyhood\n",
    "likelyhood = sum(p.y for p in patient_data) / len(patient_data)\n",
    "log_likelyhood = sum(log(likelyhood) * p.y + \\\n",
    "                         log(1.0 - likelyhood) * (1.0 - p.y) for p in patient_data)\n",
    "\n",
    "# R^2\n",
    "r2 = (log_likelyhood - log_likelyhood_fit) / (log_likelyhood)\n",
    "print(r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a6ed22-73f1-47ee-bdbd-4bf8c28ec0aa",
   "metadata": {},
   "source": [
    "So, we can conclude that hours of exposure is mediocre for predicting symptoms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca26a29-fca7-449d-8b96-e251a79ba939",
   "metadata": {},
   "source": [
    "## P-Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4de44d-77ca-4210-8fb3-5f546f338eae",
   "metadata": {},
   "source": [
    "However, the $R^2$ is not enough. We need to check whether we saw this data by chance rather than because of an actual relationship. This means we need to compute the p-value.\n",
    "To do so, we need to use the $chi-square \\; distribution$. If we take each value in a standard normal distribution (mean 0 and std 1) and square it that will give us this distribution with one degree of freedom. In our case the degrees of fredoom is one since our parameters are 2 (one X and one Y), $df = n -1$.\n",
    "Then, the formula to get $chi-square$ value is the following:\n",
    "- $\\chi^2 = 2(log\\;likeliihood\\;fit) - (log\\;likelihood)$.\n",
    "\n",
    "Once we got the value  of the distribution we can campute its corrisponding p-value through this formula:\n",
    "- $p-value = chi(2(log\\;likeliihood\\;fit) - (log\\;likelihood))$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ff729039-9e07-41e8-85e6-f1c23737f20e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0016604875618753787\n"
     ]
    }
   ],
   "source": [
    "# Example 6-15 P-value for a given logistic regression\n",
    "import pandas as pd\n",
    "from math import log, exp\n",
    "from scipy.stats import chi2\n",
    "\n",
    "# Data\n",
    "patient_data = list(pd.read_csv(\"https://bit.ly/33ebs2R\", delimiter=\",\").itertuples())\n",
    "\n",
    "# Set beta0 and beta1\n",
    "b0 = -3.17576395\n",
    "b1 = 0.69267212\n",
    "\n",
    "\n",
    "# Logistic function\n",
    "def logistic_function(x):\n",
    "    p = 1.0 / (1.0 + exp(-(b0 + b1 * x)))\n",
    "    return p\n",
    "\n",
    "# Log-likelyhood fit\n",
    "log_likelyhood_fit = sum(log(logistic_function(p.x)) * p.y + \\\n",
    "                         log(1.0 - logistic_function(p.x)) * (1.0 - p.y) for p in patient_data)\n",
    "\n",
    "# Log-likelyhood\n",
    "likelyhood = sum(p.y for p in patient_data) / len(patient_data)\n",
    "log_likelyhood = sum(log(likelyhood) * p.y + \\\n",
    "                         log(1.0 - likelyhood) * (1.0 - p.y) for p in patient_data)\n",
    "\n",
    "# P-value\n",
    "chi2_value = 2 * (log_likelyhood_fit - log_likelyhood)\n",
    "p_value = chi2.pdf(chi2_value, 1)  # 1 is the df\n",
    "print(p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b126eb3-4c3e-446f-bade-1e715e04986a",
   "metadata": {},
   "source": [
    "This p-value is way below the .05 threshold, meaning that this relationship did not happen by random chance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd687808-b5a2-44dd-b695-eff229e0e1c6",
   "metadata": {},
   "source": [
    "## Train/Test Splits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc68b48-35c4-44b5-b50e-e7d67cb4ef7c",
   "metadata": {},
   "source": [
    "When we are dealing with more variables rely on statistical metric like R^2 and p-values become less practical, that's why we can use also here the train/test split methodology (to reduce over-fitting as well)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2c7d09d8-0d13-4232-8585-bd912bc8f9ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.61111111 0.61111111 0.61111111]\n",
      "Accuracy Mean: 0.6111111111111112 (std=0.0)\n"
     ]
    }
   ],
   "source": [
    "# Example 6-16 Performing a logistic regressiion with three-fold CV\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "# Data\n",
    "df = pd.read_csv(\"https://tinyurl.com/y6r7qjrp\", delimiter=\",\")\n",
    "\n",
    "# X\n",
    "X = df.values[:, :-1]\n",
    "# Y\n",
    "Y = df.values[:, -1]\n",
    "\n",
    "# Log. regression - k=3. shuffle = True -> Whether to shuffle the data \n",
    "# before splitting into batches. Note that the samples within each split \n",
    "# will not be shuffled.\n",
    "kfold = KFold(n_splits=3, random_state=7, shuffle=True)\n",
    "model = LogisticRegression(penalty=\"none\")\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "print(results)\n",
    "print(f\"Accuracy Mean: {results.mean()} (std={results.std()})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b06bbeb-a569-43c2-baf1-db0c84b0b332",
   "metadata": {},
   "source": [
    "## Confusion Matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3583e539-7ce1-45d8-9748-1231b68e6695",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
