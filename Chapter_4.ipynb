{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4afabda0-0e30-4624-b692-6ead9a5cf089",
   "metadata": {},
   "source": [
    "# Linear Algebra"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5e1bfd-cf74-402b-8c61-7dfbab87236d",
   "metadata": {},
   "source": [
    "## What is a vector?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359f9f55-b8ac-4c3a-9953-94bac286f9ea",
   "metadata": {},
   "source": [
    "A vector is an arrow in space with a specific direction and lenght, often representing a piece of data. We declare a vector this way:\n",
    "- $\\vec{v} = \\begin{bmatrix}x \\\\ y\\end{bmatrix}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b70a44f-e20f-4c0a-ab1b-bbaf1ab3639f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 2]\n"
     ]
    }
   ],
   "source": [
    "# Example 4-1 Declaring a vector in Python\n",
    "v = [3,2]\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c5ea918-1a99-4e5a-9c5d-db8c104390f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 2]\n"
     ]
    }
   ],
   "source": [
    "# Example 4-2 Declaring a vector in Python using NumPy\n",
    "import numpy as np\n",
    "v = np.array([3, 2])\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ff4040-33e1-4e18-af03-5cf157e817bf",
   "metadata": {},
   "source": [
    "We can declare vectors that have more than 2 dimensions, like the following:\n",
    "- $\\vec{v} = \\begin{bmatrix}x \\\\ y \\\\ z\\end{bmatrix}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3711ba80-278a-4644-a3b2-b8a1206b720a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 1 2]\n"
     ]
    }
   ],
   "source": [
    "# Example 4-3 Declaring a three-dimensional vector in Python using NumPy\n",
    "import numpy as np\n",
    "v = np.array([4, 1, 2])\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00ba5255-6d6c-4c8f-8a89-320d889d1822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 1 2 5 7]\n"
     ]
    }
   ],
   "source": [
    "# Example 4-4 Declaring a five-dimensional vector in Python using NumPy\n",
    "import numpy as np\n",
    "v = np.array([4, 1, 2, 5, 7])\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb83369-58b9-4172-8afd-6429af296e40",
   "metadata": {},
   "source": [
    "### Adding and Combining Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8908ff6f-0d9d-4097-af48-12b54ae6f719",
   "metadata": {},
   "source": [
    "If we want to combine vectors we simply need to add the respective x-values and y-values into a new vector. We can visually do this by connecting graphically the second to the first. The point we end up is a new vector, the result of summing the two vectors.\n",
    "The order of operation does not matter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b012887-d7b8-4df3-80f4-153e734b4d73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 1]\n"
     ]
    }
   ],
   "source": [
    "# Example 4-5 Adding two vectors in Python using NumPy\n",
    "import numpy as np\n",
    "v = np.array([3, 2])\n",
    "w = np.array([2, -1])\n",
    "v_plus_w = v + w\n",
    "print(v_plus_w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8ffbb2-52c3-43c5-8295-e8a63846ebb5",
   "metadata": {},
   "source": [
    "### Scaling Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9951aeca-a6e2-486b-a412-a27cc9f876fc",
   "metadata": {},
   "source": [
    "Scaling is growing or shrinking a vector's lenght. We do it by multiplying or scaling it with a single value, known as a scalar. Mathematically, we simply multiply each element of our vectory by the scalar value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "988037ea-3926-4473-b12e-bfcc5d642bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6. 2.]\n"
     ]
    }
   ],
   "source": [
    "# Exampkle 4-6 Scaling a number in Python using NumPy\n",
    "import numpy as np\n",
    "v = np.array([3, 1])\n",
    "scaled_v = v * 2.0\n",
    "print(scaled_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba42c8f-f943-4097-9924-c442ee1cb5ff",
   "metadata": {},
   "source": [
    "It is important to note that scaling a vector does not change its direction, only its magnitude apart when we multiply it by a negative number which flips it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b55cb86-e0ae-435e-ace1-1ec5770815f3",
   "metadata": {},
   "source": [
    "### Span and Linear Dependence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c70d44-b365-4f69-95e0-6f2f53deb021",
   "metadata": {},
   "source": [
    "These two operations, adding two vectors and scaling them, allows us to create whatever vector we want. This span, is in most cases unlimited. This applies when we have linearly indipendent vectors, so, when their directions are different. Otherwise, when they are on the same line, we are stuck on that line, whatever we add or use as a scaling value, at most we can go to negative values, that is because they are linearly dependent.\n",
    "\n",
    "When we have vectors that are linearly dependent on a 3 or more dimensions, we often get stuck on a plane in a smaller number of dimensions. And, we do care about linear dependence because a lot of problems become unsolvable or difficult when vectors are linearly indipendent. We will use the determinant to check for linear dependence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519a04ff",
   "metadata": {},
   "source": [
    "## Linear Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ffd8b2e",
   "metadata": {},
   "source": [
    "The concept of adding two vectors with fixed direction in ordeer to get different vectors is important. Indeed, we can get whatever vector we want execept in cases of linear dependence. This means we can use a vector to transform another vector in a function-like manner."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6467bd37",
   "metadata": {},
   "source": [
    "### Basis Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d615ba73",
   "metadata": {},
   "source": [
    "Let's say we have two simple vectors $\\hat{i}$ and $\\hat{j}$ and call them $basis$ $vectors$, which are used to describe transformations on other vectors. They tipically have a lenght of 1 and point in perpendicular positive directions. These simple vectors are our building blocks, and are expressed (or packaged) in a $2x2$ matrix:\n",
    "\n",
    "- $\\hat{i} = \\begin{bmatrix}1 \\\\ 0\\end{bmatrix}$;\n",
    "- $\\hat{j}= \\begin{bmatrix}0 \\\\ 1\\end{bmatrix}$,\n",
    "- $basis$ $vector$ $= \\begin{bmatrix}1,0\\\\0,1\\end{bmatrix}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703b5f65",
   "metadata": {},
   "source": [
    "With this in mind, let's call the result of this matrix our vector v, $\\hat{v}$, which points at $(1,1)$. Now, we can stretch our simple vectors in order to allow our vector $\\hat{v}$ to land at $(3,2)$:\n",
    "- $\\hat{i} = 3*\\begin{bmatrix}1 \\\\ 0\\end{bmatrix} = \\begin{bmatrix}3 \\\\ 0\\end{bmatrix}$;\n",
    "- $\\hat{j} = 2*\\begin{bmatrix}0 \\\\ 1\\end{bmatrix} = \\begin{bmatrix}0 \\\\ 2\\end{bmatrix}$,\n",
    "- $\\hat{v} = \\begin{bmatrix}3 \\\\ 0\\end{bmatrix} + \\begin{bmatrix}0 \\\\ 2\\end{bmatrix} = \\begin{bmatrix}3,0\\\\0,2\\end{bmatrix}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380d0c83",
   "metadata": {},
   "source": [
    "It is important to note that we cannot have transformations that are nonlinear, resultying then in curvy or squiggly transformations that no longer respect a straight line."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcea2620",
   "metadata": {},
   "source": [
    "## Matrix Vector Multiplication"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb5ae27",
   "metadata": {},
   "source": [
    "We can transform an existing vector v given basis vectors i and j packaged as a matrix. This transformation is known as matrix vector multiplication. It is a shortcut for adding together i and j and then scaling it with the vector v.\n",
    "NumPy populates the matrix as a row rather than a column, so, we need to transpose them if we want to break out the basis vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a038df91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 2]\n"
     ]
    }
   ],
   "source": [
    "# Example 4-7 Matrix vector multiplication in NumPy\n",
    "import numpy as np\n",
    "\n",
    "basis = np.array([[3, 0],\n",
    "                  [0, 2]]\n",
    "                )\n",
    "\n",
    "v = np.array([1, 1])\n",
    "\n",
    "new_vector_v = basis.dot(v)\n",
    "print(new_vector_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "97c23da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 0]\n",
      " [0 3]]\n",
      "[2 3]\n"
     ]
    }
   ],
   "source": [
    "# Example 4-8 Separating the basis vectors and applying them as a transformation\n",
    "import numpy as np\n",
    "i_hat = np.array([2, 0])\n",
    "j_hat = np.array([0, 3])\n",
    "basis = np.array([i_hat, j_hat]).transpose()\n",
    "print(basis)\n",
    "v = np.array([1, 1])\n",
    "new_vector_v = basis.dot(v)\n",
    "print(new_vector_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f7ca9210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 0]\n",
      "[0 3]\n",
      "[[2 0]\n",
      " [0 3]]\n",
      "[4 3]\n"
     ]
    }
   ],
   "source": [
    "# Example 4-9 Transforming a vector using NumPy\n",
    "import numpy as np\n",
    "\n",
    "i_hat = np.array([1, 0]) * 2\n",
    "print(i_hat)\n",
    "j_hat = np.array([0, 1]) * 3\n",
    "print(j_hat)\n",
    "basis = np.array([i_hat, j_hat]).transpose()\n",
    "print(basis)\n",
    "v = np.array([2, 1])\n",
    "new_vector_v = basis.dot(v)\n",
    "print(new_vector_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c8cb7883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2  2]\n",
      " [ 3 -1]]\n",
      "[6 5]\n"
     ]
    }
   ],
   "source": [
    "# Example 4-10 A more complicated transformation\n",
    "import numpy as np\n",
    "\n",
    "i_hat = np.array([2, 3])\n",
    "j_hat = np.array([2, -1])\n",
    "basis = np.array([i_hat, j_hat]).transpose()\n",
    "print(basis)\n",
    "\n",
    "v = np.array([2, 1])\n",
    "new_vector_v = basis.dot(v)\n",
    "print(new_vector_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7691e7",
   "metadata": {},
   "source": [
    "### Matrix Multiplication"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151f7101",
   "metadata": {},
   "source": [
    "We learned how to multiply a vector (vector v) and a matrix (basis vector). Let's now learn how to multiply different matrix together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bdfb1031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0 -1]\n",
      " [ 1  0]]\n",
      "[[1 1]\n",
      " [0 1]]\n",
      "[-1  1]\n"
     ]
    }
   ],
   "source": [
    "# Example 4-11 Combining two transformations\n",
    "import numpy as np\n",
    "\n",
    "# First matrix composed of simple vectors\n",
    "i_hat1 = np.array([0, 1])\n",
    "j_hat1 = np.array([-1, 0])\n",
    "\n",
    "transform1 = np.array([i_hat1, j_hat1]).transpose()\n",
    "print(transform1)\n",
    "\n",
    "# Second matrix composed of simple vectors\n",
    "i_hat2 = np.array([1, 0])\n",
    "j_hat2 = np.array([1, 1])\n",
    "\n",
    "transform2 = np.array([i_hat2, j_hat2]).transpose()\n",
    "print(transform2)\n",
    "\n",
    "# Combine these two matrices\n",
    "combined = transform2 @ transform1\n",
    "\n",
    "# Multiply it with our vector v\n",
    "v = np.array([1, 2])\n",
    "\n",
    "print(combined.dot(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f11450ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0 -1]\n",
      " [ 1  0]]\n",
      "[[1 1]\n",
      " [0 1]]\n",
      "[-2  3]\n"
     ]
    }
   ],
   "source": [
    "# Example 4-12 Applying the transformation in reverse\n",
    "import numpy as np\n",
    "\n",
    "i_hat1 = np.array([0, 1])\n",
    "j_hat1 = np.array([-1, 0])\n",
    "\n",
    "transform1 = np.array([i_hat1, j_hat1]).transpose()\n",
    "print(transform1)\n",
    "\n",
    "i_hat2 = np.array([1, 0])\n",
    "j_hat2 = np.array([1, 1])\n",
    "\n",
    "transform2 = np.array([i_hat2, j_hat2]).transpose()\n",
    "print(transform2)\n",
    "\n",
    "combined = transform1 @ transform2\n",
    "\n",
    "v = np.array([1, 2])\n",
    "\n",
    "print(combined.dot(v))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13517799-445b-470f-82bf-d2de2d407e2d",
   "metadata": {},
   "source": [
    "### Determinants"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e6cec3-ae46-423c-ad45-67b61430bc5b",
   "metadata": {},
   "source": [
    "Determinants describe how much a sampled area in a vector space changes in scale with with linear transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5fd6703e-4e64-4834-992f-22ce3c11b6a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3 0]\n",
      " [0 2]]\n",
      "6.0\n"
     ]
    }
   ],
   "source": [
    "# Example 4-13 Calculating determinant\n",
    "from numpy.linalg import det\n",
    "from numpy import array\n",
    "\n",
    "i_hat = array([3, 0])\n",
    "j_hat = array([0, 2])\n",
    "\n",
    "basis = array([i_hat, j_hat]).transpose()\n",
    "print(basis)\n",
    "\n",
    "determinant = det(basis)\n",
    "print(determinant)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e11589-ed7b-4e91-9422-57380a630b5f",
   "metadata": {},
   "source": [
    "Simple shears and rotations shouldn't affect the determinant, as the area will not change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5932ed0c-1c3e-4e76-9e1b-39c7c7dc2d31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1]\n",
      " [0 1]]\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# Example 4-14 A determinant for a shear\n",
    "from numpy.linalg import det\n",
    "from numpy import array\n",
    "\n",
    "i_hat = array([1, 0])\n",
    "j_hat = array([1, 1])\n",
    "\n",
    "basis = array([i_hat, j_hat]).transpose()\n",
    "print(basis)\n",
    "\n",
    "determinant = det(basis)\n",
    "print(determinant)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5afcb109-0c28-49f5-b6ce-a1d422c139c1",
   "metadata": {},
   "source": [
    "But the scaling will increase or decrease the determinant, as that will increase or decrease the sampled area. When the orientation flips, then the determinant will be negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f94ca948-7794-4f16-9a83-b4aeb0189db8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-2  1]\n",
      " [ 1  2]]\n",
      "-5.0\n"
     ]
    }
   ],
   "source": [
    "# Example 4-15 A negative determinant\n",
    "from numpy.linalg import det\n",
    "from numpy import array\n",
    "\n",
    "i_hat = array([-2, 1])\n",
    "j_hat = array([1, 2])\n",
    "\n",
    "basis = array([i_hat, j_hat]).transpose()\n",
    "print(basis)\n",
    "\n",
    "determinant = round(det(basis), 2)\n",
    "print(determinant)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b905fde-83a6-4576-a3fa-456a13a2b13a",
   "metadata": {},
   "source": [
    "But by far the most critical piece of information the determinant tells you is whether the transformation is linearly dependent or not. If you have a determinant of zero, that means all of the space has been squished into a lesser dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "271eda86-8c4b-4be7-9f5c-3cf5319a7ab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-2.   3. ]\n",
      " [ 1.  -1.5]]\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# Example 4-16 A determinant of zero\n",
    "from numpy.linalg import det\n",
    "from numpy import array\n",
    "\n",
    "i_hat = array([-2, 1])\n",
    "j_hat = array([3, -1.5])\n",
    "\n",
    "basis = array([i_hat, j_hat]).transpose()\n",
    "print(basis)\n",
    "\n",
    "determinant = det(basis)\n",
    "print(determinant)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0421ef4-53dd-45ee-bfb1-41fcd1f011ff",
   "metadata": {},
   "source": [
    "So testing for a zero determinant is highly helpful to determine if a transformation has linear dependence. When you encounter this, you will likely find a difficult or unsolvable problem on your hands."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ece511c-bd21-47e1-bd69-4d2ca5e67530",
   "metadata": {},
   "source": [
    "### Special Types of Matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb2bfc3-8a09-4c0f-b856-7498949149e3",
   "metadata": {},
   "source": [
    "We have different kind of matrices:\n",
    "- Square matrix;\n",
    "- Identity matrix;\n",
    "- Inverse matrix;\n",
    "- Diagonal matrix;\n",
    "- Triangular matrix;\n",
    "- Sparse matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3af035d-938c-4060-ad99-aa96510e30aa",
   "metadata": {},
   "source": [
    "#### Square matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be5aaca-dc23-4bfd-a758-f22e12872454",
   "metadata": {},
   "source": [
    "The square matrix is a matrix that has an equal number of rows and columns. They are primarily used to represent linear transformations and are a requirment for many operations (es. eigendecomposition).\n",
    "Here an example: \\begin{bmatrix}3&0&9\\\\0&2&4\\\\3&5&8\\end{bmatrix}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e89dac9-ebfc-403e-8e47-eabccce3aad3",
   "metadata": {},
   "source": [
    "#### Identity matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c50ae4-407a-4af8-a7af-439d17bb09ca",
   "metadata": {},
   "source": [
    "The identity matrix is a square matrix that has a diagonal of 1s while the other values are 0. They play a big role in solving system of equations since the identity matrix essentially represents the result of a linear transformation, as will be explained later.\n",
    "Here an example: \\begin{bmatrix}1&0&0\\\\0&1&0\\\\0&0&1\\end{bmatrix}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1998a6-da3f-44c2-9efc-7cce2b6ee946",
   "metadata": {},
   "source": [
    "#### Inverse matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dee5fe7-16ea-4c41-88e7-e7c1c60bd7d8",
   "metadata": {},
   "source": [
    "An inverse matrix is just a matrix that undoes the transformation of another matrix. Let's say we have a matrix called A:\n",
    "- $A$: \\begin{bmatrix}4&2&4\\\\5&3&7\\\\9&3&6\\end{bmatrix}\n",
    "\n",
    "Then, the inverse of $A$ is defined as $A^{-1}$ and if we multiply it with the original matrix A we end up with the identity matrix:\n",
    "- $A^{-1}$: \\begin{bmatrix}-\\dfrac{1}{2}&0&\\dfrac{1}{3}\\\\5.5&-2&\\dfrac{4}{3}\\\\-2&1&\\dfrac{1}{3}\\end{bmatrix}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ddcea4e-ae27-4672-be72-5f7b137550be",
   "metadata": {},
   "source": [
    "#### Diagonal matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d7c0ee-cc4f-42cd-bad1-827346d50ddb",
   "metadata": {},
   "source": [
    "Similar to identity matrix is the diagonal matrix, which has a diagonal of nonzero values while the rest of the values are 0.\n",
    "Here an example: \\begin{bmatrix}4&0&0\\\\0&3&0\\\\0&0&6\\end{bmatrix}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0cb1be8-c875-412f-adf2-dff0284f00b4",
   "metadata": {},
   "source": [
    "#### Triangular matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde8c133-3317-4286-a307-24f717066e34",
   "metadata": {},
   "source": [
    "Triangular matrix has a diagonal of nonzero values in front of a triangle of values, while the rest of the values are 0.\n",
    "Here an example:\n",
    "\\begin{bmatrix}4&2&4\\\\0&3&7\\\\0&0&6\\end{bmatrix}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074235d1-1753-4001-ac39-cfe5453ede4e",
   "metadata": {},
   "source": [
    "#### Sparse matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0349c758-3d48-47c2-8c48-d34093384ff9",
   "metadata": {},
   "source": [
    "There are matrices that are mostrly zeros and have very few nonzero elements. These are called sparse matrix. From a computing standpoint they provide opportunities to create efficiency. Indeed, if a matrix has mostly 0s, a sparse matrix implementation will just keep track of the cells that are nonzero. Thus, when we have large matrices that are sparse we might explicitly use a sparse function to create our matrix.\n",
    "Here an example: \\begin{bmatrix}0&0&4\\\\0&0&0\\\\0&0&0\\\\0&0&0\\end{bmatrix}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e13657-4650-4064-9e32-87be104fd2ed",
   "metadata": {
    "tags": []
   },
   "source": [
    "### System of Equations and Inverse Matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7d3284-dd78-4c05-bb09-4bffb4335c21",
   "metadata": {},
   "source": [
    "One of the usecases of linear algebra is to solve system of equations. Let's say we jave this system:\n",
    "- $4x + 2y + 4z = 44$;\n",
    "- $5x + 3y + 7z = 56$;\n",
    "- $9x + 3y + 6z = 72$.\n",
    "\n",
    "To solve it through linear algebra we need to express this problem in terms of matrices. So, we need to extract the coefficients into matriix $A$, the values on the right side of the equation into matrix $B$ and the unknown variables into matrix $X$:\n",
    "- $A$ = \\begin{bmatrix}4&2&4\\\\5&3&7\\\\9&3&6\\end{bmatrix}\n",
    "- $B$ = \\begin{bmatrix}44\\\\56\\\\72\\end{bmatrix}\n",
    "- $X$ = \\begin{bmatrix}x\\\\y\\\\z\\end{bmatrix}\n",
    "\n",
    "The function for a linear system of equations is $AX = B$. To solve it we need to re-arrange and solve for $X$, thus, we need to get rid of matrix $A$; we do so by multiplying both sides with its inverse, $A^{-1}$. Doing so, we end up with $X = B*A^{-1}$.\n",
    "As anticipated before multiplying the inverse by its original matrix will create the identity matrix, which for linear algebra is the equivalent of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "892ed581-a57d-425d-ad86-c9a1ccb05863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix([[4, 2, 4], [5, 3, 7], [9, 3, 6]])\n",
      "Matrix([[-1/2, 0, 1/3], [11/2, -2, -4/3], [-2, 1, 1/3]])\n",
      "Matrix([[1, 0, 0], [0, 1, 0], [0, 0, 1]])\n"
     ]
    }
   ],
   "source": [
    "# Example 4-17 Using SymPy to study the inverse and identity matrix\n",
    "from sympy import *\n",
    "\n",
    "# 4x + 2y + 4z = 44\n",
    "# 5x + 3y + 7z = 56\n",
    "# 9x + 3y + 6z = 72\n",
    "\n",
    "A = Matrix([\n",
    "    [4, 2, 4],\n",
    "    [5, 3, 7],\n",
    "    [9, 3, 6]\n",
    "])\n",
    "print(A)\n",
    "\n",
    "# Get the inverse\n",
    "inverse = A.inv()\n",
    "print(inverse)\n",
    "\n",
    "# Get identity matrix\n",
    "identity = inverse * A\n",
    "print(identity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "088cc9e3-80ef-4554-86f5-bef7fc712e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2. 34. -8.]\n"
     ]
    }
   ],
   "source": [
    "# Example 4-18 Using NumPy to solve a system of equations\n",
    "from numpy.linalg import inv\n",
    "from numpy import array\n",
    "\n",
    "# 4x + 2y + 4z = 44\n",
    "# 5x + 3y + 7z = 56\n",
    "# 9x + 3y + 6z = 72\n",
    "\n",
    "A = array([\n",
    "    [4, 2, 4],\n",
    "    [5, 3, 7],\n",
    "    [9, 3, 6]\n",
    "])\n",
    "\n",
    "B = array([44,\n",
    "           56,\n",
    "           72])\n",
    "\n",
    "# Get X -> $A^-1 * B\n",
    "X = inv(A).dot(B)\n",
    "print(X)  # X = 2, Y = 34 and Z = -8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e07b3585-af1f-4bf4-8044-88e432b6c66b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix([[2], [34], [-8]])\n"
     ]
    }
   ],
   "source": [
    "# Example 4-19 Using SymPy to solve a system of equations\n",
    "from sympy import *\n",
    "\n",
    "# 4x + 2y + 4z = 44\n",
    "# 5x + 3y + 7z = 56\n",
    "# 9x + 3y + 6z = 72\n",
    "\n",
    "A = Matrix([\n",
    "    [4, 2, 4],\n",
    "    [5, 3, 7],\n",
    "    [9, 3, 6]\n",
    "])\n",
    "\n",
    "B = Matrix([44,\n",
    "           56,\n",
    "           72])\n",
    "\n",
    "X = A.inv() * B\n",
    "print(X)  # X = 2, Y = 34 and Z = -8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a71fa00-1851-45c3-92e9-76ff3cfd7716",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Eigenvectors and Eigenvalues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1213926-7a2f-4624-9db8-20abbc9c2d0f",
   "metadata": {},
   "source": [
    "Matrix decomposition is breaking up a matrix into its basic components, much like factoring numbers (e.g. 10 can be factored to 2 * 5). This is helpful for tasks like finding the inverse and calculating determinants, as well as linear regressions. One of the methods to decompose a matrix is called $eigendecomposition$.\n",
    "In $eigendecomposition$ there are two components, $eigenvalues$ and $eigenvectors$, denoted by $\\lambda$ and $\\nu$.\n",
    "If we have a square matrix $A$, it has the following eigenvalue equation:\n",
    "- $A\\nu = \\lambda\\nu$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5868ba47-aff6-4f3e-b347-63bc2da1705d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.46410162  6.46410162]\n",
      "\n",
      "\n",
      "[[-0.80689822 -0.34372377]\n",
      " [ 0.59069049 -0.9390708 ]]\n"
     ]
    }
   ],
   "source": [
    "# Example 4-20  Performing eigendecomposition in NumPy\n",
    "from numpy import array, diag\n",
    "from numpy.linalg import eig, inv\n",
    "\n",
    "A = array([\n",
    "    [1, 2],\n",
    "    [4, 5]\n",
    "])\n",
    "\n",
    "eigenvals, eigenvecs = eig(A)\n",
    "\n",
    "print(eigenvals)\n",
    "print(\"\\n\")\n",
    "print(eigenvecs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c97a0f3-2955-4cd2-84da-fb4ad5607727",
   "metadata": {},
   "source": [
    "In order to recompose our original matrix we have to follow this formula:\n",
    "- $A = Q^{-1}*\\Lambda*Q$.\n",
    "\n",
    "$Q$ is the eigenvectors, $\\Lambda$ is the eigenvalues in diagonal form and $Q^{-1}$ is just the inverse of $Q$. In $\\Lambda$ we are just padding the vector into a diagonal matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bfb17e39-b3f9-40d3-ac0a-612aff25771c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.46410162  6.46410162]\n",
      "\n",
      "\n",
      "[[-0.80689822 -0.34372377]\n",
      " [ 0.59069049 -0.9390708 ]]\n",
      "\n",
      "\n",
      "[[1. 2.]\n",
      " [4. 5.]]\n"
     ]
    }
   ],
   "source": [
    "# Example 4-21 Decomposing and recomposing in NumPy\n",
    "from numpy import array, diag\n",
    "from numpy.linalg import eig, inv\n",
    "\n",
    "A = array([\n",
    "    [1, 2],\n",
    "    [4, 5]\n",
    "])\n",
    "\n",
    "eigenvals, eigenvecs = eig(A)\n",
    "\n",
    "print(eigenvals)\n",
    "print(\"\\n\")\n",
    "print(eigenvecs)\n",
    "print(\"\\n\")\n",
    "\n",
    "Q = eigenvecs\n",
    "inverse_Q = inv(Q)\n",
    "V = diag(eigenvals)\n",
    "\n",
    "original_matrix = Q @ V @ inverse_Q\n",
    "print(original_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
